@article{,
   author = {Xiaonan Guo and Jian Liu and Yingying Chen},
   title = {When Your Wearables Become Your Fitness Mate},
   year = {2020},
}
@inproceedings{Zhou2016,
   abstract = {Relation classification is an important semantic processing task in the field of natural language processing (NLP). State-of-the-art systems still rely on lexical resources such as WordNet or NLP systems like dependency parser and named entity recognizers (NER) to get high-level features. Another challenge is that important information can appear at any position in the sentence. To tackle these problems, we propose Attention-Based Bidirectional Long Short-Term Memory Networks(Att-BLSTM) to capture the most important semantic information in a sentence. The experimental results on the SemEval-2010 relation classification task show that our method outperforms most of the existing methods, with only word vectors.},
   author = {Peng Zhou and Wei Shi and Jun Tian and Zhenyu Qi and Bingchen Li and Hongwei Hao and Bo Xu},
   doi = {10.18653/v1/p16-2034},
   isbn = {9781510827592},
   booktitle = {54th Annual Meeting of the Association for Computational Linguistics, ACL 2016 - Short Papers},
   pages = {207-212},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Attention-based bidirectional long short-term memory networks for relation classification},
   year = {2016},
}
@book{,
   author = {Ronald Mutegeki and Dong Seog Han},
   isbn = {9781728149851},
   publisher = {IEEE},
   title = {A CNN-LSTM Approach to Human Activity Recognition},
   year = {2020},
}
@article{,
   author = {Jason Brownlee},
   title = {1D Convolutional Neural Network Models for Human Activity Recognition},
   url = {https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/},
   year = {2020},
}
@article{Bersch2014,
   abstract = {It is known that parameter selection for data sampling frequency and segmentation techniques (including different methods and window sizes) has an impact on the classification accuracy. For Ambient Assisted Living (AAL), no clear information to select these parameters exists, hence a wide variety and inconsistency across today's literature is observed. This paper presents the empirical investigation of different data sampling rates, segmentation techniques and segmentation window sizes and their effect on the accuracy of Activity of Daily Living (ADL) event classification and computational load for two different accelerometer sensor datasets. The study is conducted using an ANalysis Of VAriance (ANOVA) based on 32 different window sizes, three different segmentation algorithm (with and without overlap, totaling in six different parameters) and six sampling frequencies for nine common classification algorithms. The classification accuracy is based on a feature vector consisting of Root Mean Square (RMS), Mean, Signal Magnitude Area (SMA), Signal Vector Magnitude (here SMV), Energy, Entropy, FFTPeak, Standard Deviation (STD). The results are presented alongside recommendations for the parameter selection on the basis of the best performing parameter combinations that are identified by means of the corresponding Pareto curve. © 2014 by the authors; licensee MDPI, Basel, Switzerland.},
   author = {Sebastian D. Bersch and Djamel Azzi and Rinat Khusainov and Ifeyinwa E. Achumba and Jana Ries},
   doi = {10.3390/s140304239},
   issn = {14248220},
   issue = {3},
   journal = {Sensors (Switzerland)},
   keywords = {Ambient Assisted Living (AAL),Data acquisition,Data sampling,Event classification,Optimization},
   month = {3},
   pages = {4239-4270},
   pmid = {24599189},
   publisher = {MDPI AG},
   title = {Sensor data acquisition and processing parameters for human activity classification},
   volume = {14},
   year = {2014},
}
@misc{Ignatov2017,
   abstract = {What do these dates mean? Show less https://doi.org/./j.asoc... Get rights and content Highlights • We combine a shallow CNN for local feature extraction with statistical features. • We study how time series length affects the recognition accuracy. • Limit time series length up to 1 s to enable real-time activity classification. • Limit time series length up to 1 s to enable real-time activity classification. Share Cite • Perform a cross-dataset evaluation to ensure model user-and platform-independency. • Test the solution on desktop and mobile devices to guarantee acceptable running time. • We make the source code of the model and the whole pipeline publicly available. Abstract With a widespread of various sensors embedded in mobile devices, the analysis of human daily activities becomes more common and straightforward. This task now arises in a range of applications such as healthcare monitoring, fitness tracking or user-adaptive systems, where a general model capable of instantaneous activity recognition of an arbitrary user is needed. In this paper, we present a user-independent deep learning-based approach for online human activity classification. We propose using Convolutional Neural Networks for local feature extraction together with simple statistical features that preserve information about the global form of time series. Furthermore, we investigate the impact of time series length on the recognition accuracy and limit it up to 1 s that makes possible continuous real-time activity classification. The accuracy of the proposed approach is evaluated on two commonly used WISDM and UCI datasets that contain labeled accelerometer data from 36 and 30 users respectively, and in cross-dataset experiment. The results show that the proposed model demonstrates state-of-the-art performance while requiring low computational cost and no manual feature engineering. Graphical abstract Download: Download high-res image (KB) Download: Download full-size image},
   author = {Andrey Ignatov},
   title = {Real-time human activity recognition from accelerometer data using Convolutional Neural Networks},
   url = {https://doi.org/./j.asoc...},
   year = {2017},
}
@article{Capela2015,
   abstract = {Human activity recognition (HAR), using wearable sensors, is a growing area with the potential to provide valuable information on patient mobility to rehabilitation specialists. Smartphones with accelerometer and gyroscope sensors are a convenient, minimally invasive, and low cost approach for mobility monitoring. HAR systems typically pre-process raw signals, segment the signals, and then extract features to be used in a classifier. Feature selection is a crucial step in the process to reduce potentially large data dimensionality and provide viable parameters to enable activity classification. Most HAR systems are customized to an individual research group, including a unique data set, classes, algorithms, and signal features. These data sets are obtained predominantly from able-bodied participants. In this paper, smartphone accelerometer and gyroscope sensor data were collected from populations that can benefit from human activity recognition: able-bodied, elderly, and stroke patients. Data from a consecutive sequence of 41 mobility tasks (18 different tasks) were collected for a total of 44 participants. Seventy-six signal features were calculated and subsets of these features were selected using three filter-based, classifier-independent, feature selection methods (Relief-F, Correlation-based Feature Selection, Fast Correlation Based Filter). The feature subsets were then evaluated using three generic classifiers (Naïve Bayes, Support Vector Machine, j48 Decision Tree). Common features were identified for all three populations, although the stroke population subset had some differences from both able-bodied and elderly sets. Evaluation with the three classifiers showed that the feature subsets produced similar or better accuracies than classification with the entire feature set. Therefore, since these feature subsets are classifier-independent, they should be useful for developing and improving HAR systems across and within populations.},
   author = {Nicole A. Capela and Edward D. Lemaire and Natalie Baddour},
   doi = {10.1371/journal.pone.0124414},
   issn = {19326203},
   issue = {4},
   journal = {PLoS ONE},
   month = {4},
   pmid = {25885272},
   publisher = {Public Library of Science},
   title = {Feature selection for wearable smartphone-based human activity recognition with able bodied, elderly, and stroke patients},
   volume = {10},
   year = {2015},
}
@misc{Yao2018,
   abstract = {Show more https://doi.org/./j.patcog... Get rights and content Highlights • A new method to address the multi-class windows problem in human activity recognition from sequences of activity data. • Propose a fully convolutional network architecture for dense labelling and prediction of sequences of arbitrary length. • The convolutional network method is much more efficient than CNN counterparts. • Release of a new activity dataset collected from hospitalised older people. • Demonstrate the generalisability of the method on three datasets using sample-and activity-based measures. Abstract a b c b b Share Cite Recognising human activities in sequential data from sensors is a challenging research area. A significant problem arises from the need to determine fixed sequence partitions (windows) to overcome the inability of a single sample to provide adequate information about an activity; commonly overcome by using a fixed size sliding window over consecutive samples to extract information-either handcrafted or learned features-and predicting a single label for all the samples in the window. Two key issues arise from this approach: (i) the samples in one window may not always share the same label, a problem more significant for short duration activities such as gestures. We refer to this as the multi-class windows problem. (ii) the inferencing phase is constrained by the window size selected during training while the best window size is difficult to tune in practice. We propose an efficient method for predicting the label of each sample, which we call dense labelling, in a sequence of activity data of arbitrary length based on a fully convolutional network (FCN) design. In particular, our approach overcomes the problems posed by multi-class windows and fixed size sequence partitions imposed during training. Further, our network learns both features and the classifier automatically. We conduct extensive experiments and demonstrate that our proposed approach is able to outperform the state-of-the-arts in terms of sample-based classification and activity-based label misalignment measures on three challenging datasets: Opportunity, Hand Gesture, and our new dataset-an activity dataset we release based on a wearable sensor worn by hospitalised patients.},
   author = {Rui Yao and Guosheng Lin and Qinfeng Shi and Damith C Ranasinghe},
   title = {Efficient dense labelling of human activity sequences from wearables using fully convolutional networks},
   url = {https://doi.org/./j.patcog...},
   year = {2018},
}
@article{Zebin2019,
   abstract = {Edge computing aims to integrate computing into everyday settings, enabling the system to be context-aware and private to the user. With the increasing success and popularity of deep learning methods, there is an increased demand to leverage these techniques in mobile and wearable computing scenarios. In this paper, we present an assessment of a deep human activity recognition system's memory and execution time requirements, when implemented on a mid-range smartphone class hardware and the memory implications for embedded hardware. This paper presents the design of a convolutional neural network (CNN) in the context of human activity recognition scenario. Here, layers of CNN automate the feature learning and the influence of various hyper-parameters such as the number of filters and filter size on the performance of CNN. The proposed CNN showed increased robustness with better capability of detecting activities with temporal dependence compared to models using statistical machine learning techniques. The model obtained an accuracy of 96.4% in a five-class static and dynamic activity recognition scenario. We calculated the proposed model memory consumption and execution time requirements needed for using it on a mid-range smartphone. Per-channel quantization of weights and per-layer quantization of activation to 8-bits of precision post-training produces classification accuracy within 2% of floating-point networks for dense, convolutional neural network architecture. Almost all the size and execution time reduction in the optimized model was achieved due to weight quantization. We achieved more than four times reduction in model size when optimized to 8-bit, which ensured a feasible model capable of fast on-device inference.},
   author = {Tahmina Zebin and Patricia J. Scully and Niels Peek and Alexander J. Casson and Krikor B. Ozanyan},
   doi = {10.1109/ACCESS.2019.2941836},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {Convolutional neural networks,activity recognition,deep learning,edge computing,tensorflow lite},
   pages = {133509-133520},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Design and Implementation of a Convolutional Neural Network on an Edge Computing Smartphone for Human Activity Recognition},
   volume = {7},
   year = {2019},
}
@misc{Ploetz2016,
   abstract = {Human activity recognition (HAR) in ubiquitous computing is beginning to adopt deep learning to substitute for well-established analysis techniques that rely on hand-crafted feature extraction and classification methods. However, from these isolated applications of custom deep architectures it is difficult to gain an overview of their suitability for problems ranging from the recognition of manipu-lative gestures to the segmentation and identification of physical activities like running or ascending stairs. In this paper we rigorously explore deep, convolutional, and recurrent approaches across three representative datasets that contain movement data captured with wearable sensors. We describe how to train recurrent approaches in this setting, introduce a novel regularisation approach, and illustrate how they outperform the state-of-the-art on a large benchmark dataset. We investigate the suit-ability of each model for HAR, across thousands of recognition experiments with randomly sampled model configurations, explore the impact of hy-perparameters using the fANOVA framework, and provide guidelines for the practitioner who wants to apply deep learning in their problem setting.},
   author = {Thomas Ploetz and Nils Y Hammerla and Shane Halloran and Thomas Plötz},
   title = {Deep, Convolutional, and Recurrent Models for Human Activity Recognition using Wearables},
   url = {https://www.researchgate.net/publication/301818728},
   year = {2016},
}
@article{Rashid2022,
   abstract = {Human activity recognition (HAR) is one of the key applications of health monitoring that requires continuous use of wearable devices to track daily activities. This article proposes an adaptive convolutional neural network for energy-efficient HAR (AHAR) suitable for low-power edge devices. Unlike traditional adaptive (early-exit) architecture that makes the early-exit decision based on classification confidence, AHAR proposes a novel adaptive architecture that uses an output block predictor to select a portion of the baseline architecture to use during the inference phase. The experimental results show that traditional adaptive architecture suffer from performance loss whereas our adaptive architecture provides similar or better performance as the baseline one while being energy efficient. We validate our methodology in classifying locomotion activities from two data sets - 1) Opportunity and 2) w-HAR. Compared to the fog/cloud computing approaches for the Opportunity data set, our baseline and adaptive architectures show a comparable weighted F1 score of 91.79%, and 91.57%, respectively. For the w-HAR data set, our baseline and adaptive architectures outperform the state-of-the-art works with a weighted F1 score of 97.55%, and 97.64%, respectively. Evaluation on real hardware shows that our baseline architecture is significantly energy efficient ( 422.38times less) and memory-efficient ( 14.29times less) compared to the works on the Opportunity data set. For the w-HAR data set, our baseline architecture requires 2.04times less energy and 2.18times less memory compared to the state-of-the-art work. Moreover, experimental results show that our adaptive architecture is 12.32% (Opportunity) and 11.14% (w-HAR) energy efficient than our baseline while providing similar (Opportunity) or better (w-HAR) performance with no significant memory overhead.},
   author = {Nafiul Rashid and Berken Utku Demirel and Mohammad Abdullah Al Faruque},
   doi = {10.1109/JIOT.2022.3140465},
   issn = {23274662},
   issue = {15},
   journal = {IEEE Internet of Things Journal},
   keywords = {Adaptive convolutional neural network (CNN),edge computing,human activity recognition (HAR),low power,wearable devices},
   month = {8},
   pages = {13041-13051},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {AHAR: Adaptive CNN for Energy-Efficient Human Activity Recognition in Low-Power Edge Devices},
   volume = {9},
   year = {2022},
}
@misc{Preece2009,
   abstract = {With the advent of miniaturized sensing technology, which can be body-worn, it is now possible to collect and store data on different aspects of human movement under the conditions of free living. This technology has the potential to be used in automated activity profiling systems which produce a continuous record of activity patterns over extended periods of time. Such activity profiling systems are dependent on classification algorithms which can effectively interpret body-worn sensor data and identify different activities. This article reviews the different techniques which have been used to classify normal activities and/or identify falls from body-worn sensor data. The review is structured according to the different analytical techniques and illustrates the variety of approaches which have previously been applied in this field. Although significant progress has been made in this important area, there is still significant scope for further work, particularly in the application of advanced classification techniques to problems involving many different activities. © 2009 Institute of Physics and Engineering in Medicine.},
   author = {Stephen J. Preece and John Y. Goulermas and Laurence P.J. Kenney and Dave Howard and Kenneth Meijer and Robin Crompton},
   doi = {10.1088/0967-3334/30/4/R01},
   issn = {13616579},
   issue = {4},
   journal = {Physiological Measurement},
   keywords = {Activity monitoring,Classification,Fall detection,Machine learning},
   pmid = {19342767},
   publisher = {Institute of Physics Publishing},
   title = {Activity identification using body-mounted sensors - A review of classification techniques},
   volume = {30},
   year = {2009},
}
@misc{Boureau2010,
   abstract = {Many modern visual recognition algorithms incorporate a step of spatial 'pooling', where the outputs of several nearby feature detectors are combined into a local or global 'bag of features', in a way that preserves task-related information while removing irrelevant details. Pooling is used to achieve invariance to image transformations , more compact representations, and better robustness to noise and clutter. Several papers have shown that the details of the pooling operation can greatly influence the performance, but studies have so far been purely empirical. In this paper, we show that the reasons underlying the performance of various pooling methods are obscured by several confounding factors, such as the link between the sample cardinality in a spatial pool and the resolution at which low-level features have been extracted. We provide a detailed theoretical analysis of max pooling and average pooling, and give extensive empirical comparisons for object recognition tasks.},
   author = {Y-Lan Boureau and Jean Ponce and Jean Ponce@ens Fr and Yann Lecun},
   keywords = {maximum pooling pyramid vision recognition},
   title = {A Theoretical Analysis of Feature Pooling in Visual Recognition},
   url = {https://www.researchgate.net/publication/221345753},
   year = {2010},
}
@article{Twomey2018,
   abstract = {This paper serves as a survey and empirical evaluation of the state-of-the-art in activity recognition methods using accelerometers. The paper is particularly focused on long-term activity recognition in real-world settings. In these environments, data collection is not a trivial matter; thus, there are performance trade-offs between prediction accuracy, which is not the sole system objective, and keeping the maintenance overhead at minimum levels. We examine research that has focused on the selection of activities, the features that are extracted from the accelerometer data, the segmentation of the time-series data, the locations of accelerometers, the selection and configuration trade-offs, the test/retest reliability, and the generalisation performance. Furthermore, we study these questions from an experimental platform and show, somewhat surprisingly, that many disparate experimental configurations yield comparable predictive performance on testing data. Our understanding of these results is that the experimental setup directly and indirectly defines a pathway for context to be delivered to the classifier, and that, in some settings, certain configurations are more optimal than alternatives. We conclude by identifying how the main results of this work can be used in practice, specifically in experimental configurations in challenging experimental conditions.},
   author = {Niall Twomey and Tom Diethe and Xenofon Fafoutis and Atis Elsts and Ryan McConville and Peter Flach and Ian Craddock},
   doi = {10.3390/informatics5020027},
   issn = {22279709},
   issue = {2},
   journal = {Informatics},
   keywords = {Accelerometers,Activities of daily living,Activity recognition,Machine learning,Sensors},
   month = {5},
   publisher = {MDPI Multidisciplinary Digital Publishing Institute},
   title = {A comprehensive study of activity recognition using accelerometers},
   volume = {5},
   year = {2018},
}
@article{,
   author = {M.N.Saroja K.R.Baskaran},
   title = {Machine Learning Algorithms for Human Activity Recognition},
   year = {2019},
}
@article{,
   author = {Jason Brownlee},
   title = {Evaluate Machine Learning Algorithms for Human Activity Recognition},
   year = {2020},
}
@article{,
   author = {M Lazarova and A Aleksieva-Petrova S Tsokov},
   title = {Accelerometer-based human activity recognition using 1D convolutional neural network},
   year = {2021},
}
@article{,
   author = {Ali M. Hayajneh; Maryam Hafeez; Syed Ali Raza Zaidi; Des McLernon},
   title = {TinyML Empowered Transfer Learning on the Edge},
   url = {https://ieeexplore.ieee.org/document/10459233?denied=},
   year = {2024},
}
@article{,
   author = {Belkacem Fergani Nawel Yala},
   title = {Feature extraction for human activity recognition on streaming data},
   year = {2015},
}
@article{,
   author = {Pragati Baheti},
   title = {A Simple Guide to Data Preprocessing in Machine Learning},
   url = {https://www.v7labs.com/blog/data-preprocessing-guide},
   year = {2021},
}
@article{,
   author = {Jaehun Bang 1ORCID, Thien Huynh-The Thien Huynh-The SciProfilesScilitPreprints.orgGoogle Scholar  1ORCID, Jongwon Lee 1, Jee-In Kim 2, * andSungyoung Lee 1, * Taeho Hur 1},
   note = {3. HAR Using a CNN with a Transformed Inertial Sensor Signal<br/>In this section, we explain our proposed method for transforming the inertial sensor signal using an encoding process and our CNN-based activity recognition learning procedure. First, we collected inertial raw sensory signals from a smartphone and smartwatch. The data from two different devices are synchronized to match each other and then segmented into 150 samples per 3 s window. Then, we transformed those data into color images using our proposed encoding method. The transformed signals were used as training input for a CNN, and then generated a CNN-based activity recognition model. Through this model, inertial raw sensory signal collected from a smartphone and smartwatch are input directly for classification, which produces the final activity label. Figure 1 shows the overall workflow.},
   title = {Iss2Image: A Novel Signal-Encoding Technique for CNN-Based Human Activity Recognition},
   url = {https://www.mdpi.com/1424-8220/18/11/3910},
   year = {2018},
}
@inproceedings{,
   author = {Le T. Nguyen, Bo Yu, Ole J. Mengshoel, Jiang Zhu, Pang Wu, Joy Zhang Ming Zeng},
   title = {Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors},
   year = {2014},
}
@misc{,
   author = {Deval Shah},
   note = {Procurar a parte que diz CNN para picture or time-series data, such as gyro and accelerometer},
   title = {Human Activity Recognition (HAR): Fundamentals, Models, Datasets},
   url = {https://www.v7labs.com/blog/human-activity-recognition#h3},
   year = {2023},
}
@article{,
   author = {* Gabriella Balestra, and Marco Knaflitz Samanta Rosati},
   journal = {PubMed Central},
   note = {3.1. Signal Acquisition and Experimental Setup<br/>Signals were acquired using a MIMU-based device by Medical Technology (Torino, Italy). The sensor unit consisted of a tri-axial accelerometer, a tri-axial gyroscope and a tri-axial magnetometer allowing for acquiring acceleration, rate of turn, and Earth-magnetic field data, for a total of nine signals. The measurement range was ± 4 g for the accelerometers, ± 2000°/s for the gyroscopes and ± 4 G for the magnetometers. The sampling frequency of all signals was 80 Hz. An example of signals acquired during a walk of a healthy subject is shown in Figure 1. For the purpose of this study, signals were recorded in local data storage devices and transmitted to a laptop for the following analysis.},
   title = {Comparison of Different Sets of Features for Human Activity Recognition by Wearable Sensors},
   url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6308535/},
   year = {2018},
}
@article{,
   author = {1, * Blaine A. Price, 1, * Daniel Gooch, 1 Arosha K. Bandara, 1 and Bashar Nuseibeh Mohamed Bennasar},
   journal = {MedCentral},
   note = {A group of thirty participants (age range 19–48 years) were recruited to collect this dataset in a controlled environment. They were asked to perform six activities (walking, laying, sitting, climbing up the stairs, climbing down the stairs and standing). A smartphone placed on the waist was used to capture the activities at a sampling frequency of 50 Hz using the built-in tri-axial accelerometers and 3-axial gyroscopes. In this study, we are focusing only on the data from accelerometers.},
   title = {Significant Features for Human Activity Recognition Using Tri-Axial Accelerometers},
   url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9572087/},
   year = {2022},
}
@misc{,
   author = {Tiago Angélico Ang´ and Angélico Gonç},
   title = {Convolutional Neural Network for Hand Gesture Identification on FPGAs Electrical and Computer Engineering},
   year = {2022},
}
@article{Jarning2015,
   author = {Jon M. Jarning and Kam-Ming Mok and Bjorge H. Hansen and Roald Bahr},
   title = {Application of a tri-axial accelerometer to estimate jump frequency in volleyball},
   year = {2015},
}
@article{Rueda2018,
   author = {Fernando Moya Rueda and René Grzeszick and Gernot A. Fink and Sascha Feldhorst and ten Michael Hompel},
   title = {Convolutional Neural Networks for Human Activity Recognition Using Body-Worn Sensors},
   year = {2018},
}
@article{Kautz2017,
   author = {Thomas Kautz and Benjamin H. Groh and Julius Hannink and Ulf Jensen and Holger Strubberg and Bjoern M. Eskoﬁer},
   title = {Activity recognition in beach volleyball using a Deep Convolutional Neural Network},
   year = {2017},
}
@article{Groh2015,
   author = {Benjamin H. Groh and Thomas Kautz and Dominik Schuldhaus},
   title = {IMU-based Trick Classification in Skateboarding},
   year = {2015},
}
@inproceedings{Buckley2017,
   author = {C. Buckley and M.A. O’ Reilly and Adam Vallely Farrel and L. Clark and V. Longo},
   note = {DO A TABLE LIKE THIS STUDY},
   title = {Binary Classification of Running Fatigue using a Single Inertial Measurement Unit},
   year = {2017},
}
@article{Brock2017,
   author = {Heik Brock and Yuji Ohgi and James Lee},
   title = {Learning to Judge Like a Human: Convolutional Networks for Classification of Ski Jumping Errors},
   year = {2017},
}
@article{Jensen2015,
   author = {Ulf Jensen and Marcus Schmidt and Marcos Hennig and Frank A. Dassler and Thomas Jaitner and Bjoern M. Eskofier},
   note = {FORMULAS IMU},
   title = {An IMU-based Mobile System for Golf Putt Analysis},
   year = {2015},
}
@article{,
   author = {Shai Shalev-Shwartz and Shai Ben-David},
   journal = {Published 2014 by Cambridge University Press.},
   title = {Understanding Machine Learning: From Theory to Algorithms},
   year = {2014},
}
@article{Bulling2014,
   author = {Andreas Bulling and Ulf Blanke and Bernt Schiele},
   title = {A Tutorial on Human Activity Recognition Using Body-Worn Inertial Sensors},
   year = {2014},
}
@article{Rindal2017,
   author = {Ole Marius Hoel Rindal and Trine M. Seeberg and Johannes Tjønnås and Pål Haugnes and Øyvind Sandbakk},
   note = {METHODS AND IMU AND XYZ <br/>NEURAL NETWORK - TRAIN THE MODEL},
   title = {Automatic Classification of Sub-Techniques in Classical Cross-Country Skiing Using a Machine Learning Algorithm on Micro-Sensor Data},
   year = {2017},
}
@article{Chowdhary2023,
   author = {Mahesh Chowdhary and Sayan Swapnil Saha},
   note = {TINYML AND TECHNIQUES<br/>IMU<br/>FORMULAS},
   title = {On-Sensor Online Learning and Classification Under 8 KB Memory},
   year = {2023},
}
@unpublished{,
   author = {Cust Emily E and Sweeting Alice J and Ball Kevin and Robertson Sam},
   title = {Machine and deep learning for sport-specific movement recognition: a systematic review of model development and performance},
   url = {https://www.tandfonline.com/doi/full/10.1080/02640414.2018.1521769},
   year = {2018},
}
@article{Wang2021,
   author = {Zhepeng Wang and Yawen Wu and Zhenge Jia and Yiyu Shi and Jingtong Hu},
   note = {DNN},
   title = {Lightweight Run-Time Working Memory Compression for Deployment of Deep Neural Networks on Resource-Constrained},
   year = {2021},
}
@article{,
   author = {Emmanuel Munguia Tapia and Stephen S. Intille and William Haskell and Kent Larson and Julie Wright and Abby King and Robert Friedman},
   title = {Real-Time Recognition of Physical Activities and Their Intensities Using Wireless Accelerometers and a Heart Rate Monitor },
   year = {2007},
}
@article{Lattanzi2022,
   author = {Emanuele Lattanzi and Matteo Donati and Valerio Freschi},
   title = {Exploring Artificial Neural Networks Efficiency in Tiny Wearable Devices for Human Activity Recognition},
   url = {https://www.mdpi.com/1424-8220/22/7/2637},
   year = {2022},
}
@book{,
   author = {Warden Peter and Situnayake Daniel},
   title = {TinyML - Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power Microcontrollers},
   url = {https://books.google.pt/books?hl=en&lr=&id=tn3EDwAAQBAJ&oi=fnd&pg=PP1&ots=jqllbr-7A4&sig=GAqcAA99f2EPyvOjOaddMu8gzss&redir_esc=y#v=onepage&q&f=false},
   year = {2019},
}
@article{Diab2022,
   author = {Maha S. Diab and Esther Rodriguez-Villegas},
   note = {ML aplicado na saúde},
   title = {Embedded Machine Learning Using
Microcontrollers in Wearable and Ambulatory Systems for Health and Care Applications: A Review},
   year = {2022},
}
@article{Gupta2022,
   author = {Shubham Gupta},
   note = {Interessante a referência ao TinyML, mas também a parte dos "movimentos" humanos<br/><br/><br/><br/><br/><br/>---------------------------------------------<!--td \{border: 1px solid #cccccc;\}br \{mso-data-placement:same-cell;\}-->Machine Learning applied to Human Activity RecognitionOver the past few years many algorithms have been applied to human activity recogni-<br/>tion which mainly employed supervised learning and were dependent upon human<br/>knowledge to extricate high level features. Many of such algorithms were used such as<br/>Principal Component Analysis was used in [22], support vector machine in [23], hidden<br/>markov model in [24], random forest in [25], in [26] three algorithms were analyzed<br/>such as multi-layer perception, J48 and logistic regression. Thus, all of the above men-<br/>tioned models gave fair results which could be considered acceptable but due to the<br/>basic disadvantages of these methods research in this field was kept alive in search for<br/>not only better results but which are not limited to the domain knowledge of the human.Deep Learning techniques on human activity recognitionNowadays deep learning is having major contribution towards the activity recognition<br/>research area where both convolutional neural network a recurrent neural network has<br/>shown great promise in the field. In [27] authors proposed an architecture which con-<br/>sisted of 3-layers of convolution with varying number of filters and results of the work<br/>have proved to be successful, again in [28] CNN based models not one but two has<br/>been proposed by the author namely CNN-pf and CNN-pff with accuracies over 90%.<br/>Just like CNNs, RNNs have also been an attractive approach since works like [29]<br/>where a 5-layer stacked LSTM is proposed, a simple but effective architecture where<br/>accuracy came up to be around 0.93. In another work [30] a Bi-LSTM based architec-<br/>ture is proposed which achieves accuracy up to 0.94. Not only this many works have<br/>taken hybrid models into consideration as well, such as in works like [31] where both<br/>the CNN and LSTM have been used together for the activity classification problem and<br/>not only this they have compared the model with both single layer LSTM and dense<br/>LSTM as well in which the hybrid model is seen to have the edge over the others.Another hybrid model proposed in [32] which was LSTM-CNN model which seem to<br/>have outperform all other models.TinyML as a research topicTinyML is a very new research field and exploring its effects on the other research<br/>areas will be an interesting as well as very beneficial stride towards the academia not<br/>only in a single but multiple research fields whose disadvantages is being cured by<br/>TinyML. One of the works where TinyML has been of help is in [33] where a com-<br/>pressed form of LSTM network namely TinyLSTM is being deployed in the hear-aid<br/>device and that has proved to be a successful experiment. TinyML has seen its research<br/>progress in mainly speech enhancement techniques, speech separation, denoising etc.<br/>but its advantages have not leveraged up to now in the human activity recognition field<br/>and that’s this will an important step for not only in this field but other areas where<br/>blocking points are same which TinyML promises to remove.},
   title = {A TinyML Approach to Human Activity Recognition},
   year = {2022},
}
@article{Lanraoui2023,
   author = {Nourelhouda Lanraoui and Cheyma Touati},
   note = {Referência aos reconhecimento de movimentos parecia interessante, mas o layout e organização faz-me duvidar da qualidade<br/><br/><br/><b>BOM PARA VER O EDGE IMPULSE</b>},
   title = {Tiny ML for Gesture Recognition},
   year = {2023},
}
@article{,
   author = {Ramon Sanchez‐Iborra and Antonio Skarmeta},
   note = {A parte da comparação das TinyDL toolkits, passanod assim na diagonal, pareceu-me muito útil},
   title = {Who is wearing me? TinyDL‐based user recognition in constrained personal devices},
   year = {2021},
}
@article{Xia2019,
   author = {Stephen Xia and Daniel de Godoy and Bashima Islam and Md Tamzeed Islam and Shahriar Nirjon and Peter R. Kinget and Xiaofan Jiang},
   note = {Na dúvida se poderá ser útil pela parte do "low energy"},
   title = {Improving Pedestrian Safety in Cities using Intelligent Wearable Systems},
   year = {2019},
}
@article{Yauri2022,
   author = {Ricardo Yauri and Rafael Espino},
   title = {Edge device for movement pattern classification using neural
network algorithms},
   year = {2022},
}
@article{Banbury2021,
   author = {Colby Banbury and Chuteng Zhou and Igor Fedorov and Ramon Matas Navarro and Urmish Thakker and Dibakar Gope and Vijay Janapa Reddi and Matthew Mattina and Paul N. Whatmough},
   note = {Interessante pela referência ao TinyML<br/>Related work e referências aparentemente uteis},
   title = {MICRONETS: NEURAL NETWORK ARCHITECTURES FOR DEPLOYING
TINYML APPLICATIONS ON COMMODITY MICROCONTROLLERS},
   year = {2021},
}
